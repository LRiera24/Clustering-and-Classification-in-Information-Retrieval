% This is LLNCS.DOC the documentation file of
% the LaTeX2e class from Springer-Verlag
% for Lecture Notes in Computer Science, version 2.4
\documentclass{llncs}
\usepackage{llncsdoc}
\usepackage{color}

\usepackage{algorithm}
\usepackage{amsfonts}
\usepackage[noend]{algpseudocode}


\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage[spanish]{babel}
%
\begin{document}
\markboth{Sistemas de Recuperaci\'on de Informaci\'on}{Aplicaciones del agrupamiento y de la clasificación en la RI en la Web}
\thispagestyle{empty}
\begin{flushleft}
\LARGE\bfseries Sistemas de Recuperaci\'on de Informaci\'on\\[2cm]
\end{flushleft}
\rule{\textwidth}{1pt}
\vspace{2pt}
\begin{flushright}
\Huge
\begin{tabular}{@{}l}
Aplicaciones del\\
agrupamiento y\\ 
de la clasificación\\ 
en la recuperaci\'on\\ 
de informaci\'on\\
en la Web\\[6pt]
\end{tabular}
\end{flushright}
\rule{\textwidth}{1pt}
\vfill
\begin{flushleft}
\large\itshape
\begin{tabular}{@{}l}
{\large\upshape\bfseries Autores}\\[8pt]
Laura Victoria Riera P\'erez\\[5pt]
Marcos Manuel Tirador del Riego
\end{tabular}
\end{flushleft}

%
\newpage
\pagenumbering{gobble}
\tableofcontents
\thispagestyle{empty}

\newpage
\pagenumbering{arabic}

\section{Agrupamiento}

\begin{itemize}
\item Aprendizaje no supervisado

\item Problema que resuelve
\end{itemize}

\subsection{Algunas definiciones}

\begin{itemize}
\item Flat clustering

\item Hierarchical clustering

\item Hard clustering

\item Soft clustering

\item Hip\'otesis de agrupamiento

\item Cardinalidad
\end{itemize}

\subsection{Flat clustering}

\begin{itemize}
\item Medida de similitud:

\item Medidas de evaluacion:
\begin{itemize}
	\item Criterio interno de calidad
	
	\item Criterio interno de calidad
	
	\item Pureza
	
	\item \'Indice de frontera?
	
	\item Medida F
\end{itemize}

\item Algoritmos:
\begin{itemize}
	\item K-means
	\item EM (generalizaci\'on de K-means)
\end{itemize}
\end{itemize}


\subsection{Hierarchical clustering}

\begin{itemize}
\item Hierarchical agglomerative clustering

\item Medidas de similitud:
\begin{itemize}
	\item Single link clustering
	\item Complete link clustering
	\item Centroid clustering
\end{itemize}

\item Evaluaci\'on de calidad:
\begin{itemize}
\item Group average link
\item M\'etodo de Ward
\end{itemize}

\item Divisive clustering

\item Cluster labeling

\item Algoritmos:
\begin{itemize}
	\item Algoritmo HAC
	\item Divisive Clustering
\end{itemize}
\end{itemize}

\subsection{Aplicaciones a la RI} 
\begin{itemize}
	\item Search result clustering
	
	\item Scatter-Gather
	
	\item Collection clustering
	
	\item Language modeling
	
	\item Cluster-based retrieval
\end{itemize}

\subsection{Ventajas} 

\subsection{Desventajas} 

\section{Clasificaci\'on}

	El problema de clasificaci\'on en sentido general consiste en determinar dentro un conjunto de clases a cu\'al de ellas pertenece un objeto dado. En el marco de este documento estamos interesados en estudiar la clasificaci\'on de textos. 
	
%	La forma m\'as simple de clasificaci\'on de un conjunto de textos es la denominada clasificaci\'on en dos clases. Dichas clases est\'an determinadas por un t\'opico espec\'ifico y ser\'ian: \emph{documentos sobre dicho tema } y \emph{documentos no relacionados con el tema}. Este tipo de clasificaci\'on en ocasiones es llamada \emph{filtrado}. 
%	
	La forma m\'as antigua de llevar a cabo la clasificaci\'on es manualmente. Por ejemplo, los bibliotecarios clasifican los libros de acuerdo a ciertos criterios, de modo que encontrar una informaci\'on buscada no resulte una tarea de gigante dificultad. Sin embargo la clasificaci\'on manual tiene sus l\'imites de escalabilidad. 
	
	Como alternativa podr\'ia pensarse el uso de \emph{reglas} para determinar autom\'aticamente si un texto pertenece o no a una clase determinada de documentos.
	
	Ilustremos un ejemplo de regla aplicada autom\'aticamente. Supongamos que un usuario necesita hacer una consulta en una p\'agina de noticias, por ejemplo, necesita tener actualidad sobre noticias relacionadas con las finanzas para tomar decisiones en su negocio. Al usuario entonces le podr\'ia interesar que de hacer una consulta en el sistema dicha consulta se mantenga ejecutando y le provea peri\'odicamente las noticias relativas a finanzas. 
	
	A este tipo de consultas se le denomina consultas permanentes  (o \emph{standing querys} en ingl\'es). Una consulta permanente es aquella que se ejecuta peri\'odicamente en una colecci\'on a la cual nuevos  documentos se adicionan en el tiempo. Toda consulta permanente se puede ver como un tipo de regla que se aplica a un sistema de clasificaci\'on que divide una colecci\'on en documentos que satisfacen la query y documentos que no.
	
	
%	 Por ejemplo las consultas permanentes son un ejemplo de regla aplicada autom\'aticamente. Una consulta permanente es como una consulta normal pero que es ejecutada repetidamente sobre una colecci\'on de textos a la cual se van adicionando documentos nuevos constantemente. Su finalidad es determinar si los nuevos textos pertenecen o no a la clase en cuesti\'on.
	
	Una regla captura una cierta combinaci\'on de palabras claves que identifican una clase. Reglas codificadas a mano pueden llegar a ser altamente escalable, pero crearlas y mantenerlas requiere un elevado costo en recursos humanos.
	
	Existe, sin embargo, un enfoque adicional a los dos anteriores mencionados. Nos referimos al uso de \emph{Aprendizaje de M\'aquinas}. En este enfoque el conjunto de reglas de clasificaci\'on, o en general, el criterio usado para clasificar, es aprendido de forma autom\'atica a partir de los datos de entrenamiento.
	
	Al uso del Aprendizaje de M\'aquinas en la clasificaci\'on de textos se le conoce como clasificaci\'on estad\'istica de texto (o en ingl\'es \emph{statistical text classification}) si el m\'etodo de aprendizaje usado es estad\'itico.
	
	Introduciremos a continuaci\'on la definici\'on forma del problema de clasificaci\'on de textos, en el contexto del Aprendizaje de M\'aquinas.
	
	\begin{definition} \label{Problema_de_clasificacion}
		Sea $\mathcal{{X}}$ el espacio de documentos y $\mathcal{C} := \{c_i \mid c_i \subset \mathcal{X}, i \in \{ 1,2,\dots,n\} \}$ un conjunto fijo de clases (tambi\'en llamadas categor\'ias o etiquetas). Sea adem\'as $D$ un conjunto entrenado de documentos clasificados $(d,c) \in \mathcal X \times \mathcal{C}$. El \emph{problema de la clasificaci\'on de textos} consiste en encontrar, usando m\'etodos o algoritmos de aprendizaje, una funci\'on \emph{clasificadora} $\gamma : \mathcal{X} \rightarrow \mathcal{C}$, que mapee documentos a clases, que satisfaga que $D \subset \gamma$. 	

	\end{definition}
	
	El aprendizaje que toma parte en la b\'usqueda de $\gamma$ es llamado \emph{aprendizaje supervisado} debido a que se necesita la ayuda de uno o varios expertos que creen el conjunto de entrenamiento $D$. Estos expertos son  tambi\'en quienes determinan el conjunto de clases en que se clasificar\'an los textos. Denotaremos el m\'etodo de aprendizaje supervisado descrito por $\Gamma$, el cual act\'ua como una funci\'on que mapea un conjunto de datos de entrenamiento en una funci\'on clasificadora, osea que $\Gamma(D) = \gamma$.
	
	La definici\'on dada en \ref{Problema_de_clasificacion} implica que cada documento pertenece a una sola clase. Pero existe otro tipo de problemas que permiten que un documento pertenezca a m\'as de una clase. Por ahora enfocaremos nuestra atenci\'on en el tipo de una clase.
	
	\begin{subsection}{Problemas de la Recuperaci\'on de la Informaci\'on}
	
		El aprendizaje de m\'aquinas es ampliamente usado en la actualidad para resolver una variedad de problemas de muchas esferas. La clasificaci\'on, de conjunto con la regresi\'on, es una de las grandes tareas que tiene el aprendizaje de m\'aquinas supervisado. Algunos problemas interesantes que resuelven la clasificaci\'on se encuentran dentro del marco de los Sistemas de Recuperaci\'on de la informaci\'on. Anteriormente presentábamos uno de ellos, que es la recuperaci\'on de consultas permanentes.
		
		La organizaci\'on del correo personal es otros de los ejemplos relacionados con RI que pueden ser resueltos mediante clasificaci\'on. En muchas ocasiones una persona tiene un n\'umero grande de correos en el buz\'on de entrada. A la hora de revisarlo ser\'ia deseable que pudiera dirigirse directamente a aquellos que son de inter\'es para \'el. Para ello la organizaci\'on autom\'atica del correo en carpetas podr\'ia ser una ventaja invaluable. Un ejemplo particular ser\'ia la carpeta de correo spam.
		
		Otro problema que se pudiera resolver ser\'ia la clasificaci\'on de valoraciones sobre algo en positivas o negativas. Esto tendr\'ia numerosas aplicaciones pr\'acticas como pudiera ser la selecci\'on de una pel\'icula. Un usuario podr\'ia revisar la cantidad de comentarios negativos, antes de lanzarse a disponer de dos horas de su tiempo viendo un material audiovisual que no resultar\'a muy placentero.
		
		El uso m\'as evidente que tiene la clasificaci\'on el la RI es la clasificaci\'on de documentos en t\'opicos. Esta clasificaci\'on facilitar\'ia la implementaci\'on de un motor de b\'usqueda vertical, que permita al usuario restringir su b\'usqueda al tema deseado. Un SRI con semejante caracter\'istica permite hacer una b\'usqueda m\'as precisa en las consultas m\'as especializadas por el usuario.
		
		En RI es muy \'util contar con un \'indice de los contenidos almacenados. En el proceso de creaci\'on del mencionado \'indice la clasificaci\'on puede jugar un importante papel. Por citar algunos ejemplos puede usarse para detectar el lenguaje de un documento, la segmentaci\'on y capitalizaci\'on de las palabras y el codificado del documento.

%		\begin{itemize}
%			\item[$\bullet$]
%		\end{itemize}
		
	\end{subsection}
		
	\begin{subsection}{Naive Bayes}

		Uno de los m\'etodos m\'as comunes de aprendizaje supervisado es el conocido como \emph{Naive Bayes} (NB). Este es un m\'etodo de aprendizaje probabil\'istico. La probabilidad de un documento $d$ de pertenecer a una clase $c$ se puede expresar como $P(c\mid d)$. La tarea del algoritmo es encontrar la mejor clase para cada documento $d$. Para ello NB establece que la clase m\'as apropiada para un documento es la m\'as probable, o sea
		
		\[
		c_{map} = \argmax_{c\in\mathcal{C}} P(c \mid d).
		\]
		
		La clase escogida para $d$ se denota por $c_{map}$ debido a que este m\'etodo de clasificaci\'on, de acuerdo a la clase m\'as probable para un documento dado, es conocido como \emph{maximum a posteriori} (MAP).
		
		Sin embargo la probabilidad condicional $P(c \mid d)$ es dif\'icil de determinar. Haciendo uso del \emph{Teorema de Bayes} la probabilidad anterior puede ser expresada como
		
		\[
		P(c \mid d) =\frac{ P(d\mid c) P(c)}{P(d)}.
		\]
		
		El factor de normalizaci\'on $P(d)$ es usualmente ignorado ya que no aporta informaci\'on a la hora de buscar la clase m\'as apropiada para un documento $d$, ya que este tiene el mismo efecto en todos los candidatos. Este c\'alculo puede ser simplificado si lo expresamos en t\'erminos de los t\'erminos en los documentos. Supongamos que $\{t_1, t_2, \dots , t_n \}$ son los t\'erminos que aparecen en $d$. Entonces tenemos que  
		
		\[
			c_{map} = \argmax_{c\in\mathcal{C}} P(c) P(d \mid c) = \argmax_{c\in\mathcal{C}} P(c) \prod_{1\leq k\leq n} P(t_k \mid c),
		\]
		donde $P(t_k \mid c)$ es la probabilidad de que el t\'ermino $t_k$ aparezca en un documento de la clase $c$. Podemos considerar $p(t_k \mid c)$ como una medida de qu\'e tanto demuestra el t\'ermino $t_k$ que $c$ es la clase correcta. El t\'ermino $P(c)$ es conocido como probabilidad previa (\emph{prior probability}) y en caso de que la informaci\'on aportada por los t\'erminos no sea determinante en la selecci\'on podemos siempre escoger la clase con mayor valor de $P(c)$.
		
		Para simplificar a\'un mas el c\'omputo podemos sustituir los valores anteriores por sus logaritmos. Esto reducir\'a el costo de hacer los c\'alculos y adem\'as los errores aritm\'eticos, dado que la multiplicaci\'on se transforma en suma. La clase seleccionada ser\'ia entonces
		
		\[
				c_{map} = \argmax_{c\in\mathcal{C}} \left( \log(P(c))  + \sum_{1\leq k\leq n} \log(P(t_k\mid c)) \right).
		\]
		
		Solo nos queda ver como estimamos los par\'ametros $P(c)$ y $P (t_k\mid c)$, dado que los valores reales no son posibles de calcular.	Para la probabilidad previa podemos contar la frecuencia relativa de cada clase en $D$:
		
		\[P(c) = \frac{ N_c }{N} , \]
		donde $N_c$ es el n\'umero de documentos en la clase $c$ y $N$ es el numero total de documentos. Procedemos de manera similar para la probabilidad espec\'ifica de una palabra en una clase
		\[
			P(t_k\mid c) =\frac{ T_{c,t_k}}{T_{c}},
		\]
		donde $T_{c,t_k}$ indica la cantidad de veces que ocurre  la palabra $t_k$ en todos los documentos de la clase $c$ y $T_{c}$ es la cantidad total de palabras contando repeticiones) en toda la clase $c$. Si embargo, a\'un tenemos un problema con estas f\'ormulas y es que estamos asignando probabilidad cero a todos las clases que no contengan a todas las palabras del documento a clasificar. Para evitar esto adicionamos por defecto una unidad a cada contador lo cual es conocido como \emph{Laplace smoothing}
		\[
			P(t\mid c) = \frac{T_{c,t} + 1}{T_c + |V|},	
		\]
		donde $|V|$ es el n\'umero total de t\'eminos en el vocabulario.
		
		 Es importante destacar que en este m\'etodo estamos obviando la posici\'on de las palabras. Presentamos aqu\'i los algoritmos para entrenar y clasificar usando BN que fueron textualmente copiados de \color{red}{2009 Manning C. D., Introduction to Information Retrieval, p\'agina 260. [No recuerdo como citar esto correctamente. Also recordar que agregue unos paquetes arriba que no se si se agragan aqui o en otro de los .tex]}\color{black}.
		 
		 
		 
		 \begin{algorithm}{}
		 			\caption{TrainMultinomial}
		 	\begin{algorithmic}[1]
		 		
		 		% ENTRADA / SALIDA
		 		\Require{Set of classes $\mathcal{C}$ and training set $D$.} 
%		 		\Ensure{Trained.}
		 		\State{$ V \leftarrow ExtractVocabulary(D)$}
		 		\State{$ N \leftarrow CountDocs(D)$}
		 		\For{$c \in \mathcal{C}$}
		 		\State $N_c \leftarrow CountDocsInClass(D,c)$
		 		\State $prior[c] \leftarrow N_c/N$
		 		\State $text_c \leftarrow ConcatenateTextOfAllDocsInClass(D, c)$
		 		\For{$t \in V$}
		 		\State{$T_{ct} \leftarrow CountTokensOfTerm(text_c, t)$}
		 		\EndFor
		 		\For{$t \in V$}
		 		\State{$condprob[t][c] \leftarrow \frac{T_{c,t} + 1}{\sum_{t'} (T_{c,t'} + 1)}$}
		 		\EndFor 
		 		\EndFor
		 		\State \textbf{\Return} $V, prior, condprob$
		 	\end{algorithmic}
		 \end{algorithm}
		 
		 \begin{algorithm}
		 	\caption{ApplyMultinomialNB}
		 	\begin{algorithmic}[1]
		 		
		 		% ENTRADA / SALIDA
		 		\Require{$\mathcal{C}, V$, $prior$, $condprob$, $d$} 
		 		%		 			\Ensure{Trained.}
		 		\State{$ W \leftarrow ExtractTokensFromDoc(V, d)$}
		 		\For{$c \in \mathcal{C}$}
		 		\State{$ score[c] \leftarrow \log prior[c]$}
		 		\For{$t \in W$}
		 		\State{$ score[c] +=  \log condprob[t][c]$}
		 		\EndFor
		 		\EndFor
		 		\State \textbf{\Return} $\argmax_{c\in \mathcal{C}}(score[c])$
		 	\end{algorithmic}
		 \end{algorithm}
		 
		Podemos deducir de los algoritmos que la complejidad de ambos es linear en el tiempo que toma escanear la informaci\'on. Dado que esto hay que hacerlo al menos una vez, se puede decir que este m\'etodo tiene complejidad temporal \'optima. Dicha eficiencia hace que NB sea un m\'etodo de clasificaci\'on tan usado.
	\end{subsection}
	
	
	\begin{subsection}{Feature Selection}
		Un t\'ermino con ruido (\emph{noise feature}) es aquel que al pertenecer a la representaci\'on de los documentos, provoca un aumento del error de clasificaci\'on de los datos. Por ejemplo, supongamos que tenemos una palabra que ocurre rara vez, pero que en el conjunto de entrenamiento ocurre siempre en la misma clase $c$. Entonces al clasificar un documento nuevo que contiene esta palabra, la misma provocar\'a que el clasificador se incline en cierta medida por seleccionar esta a $c$ como respuesta. Sin embargo, dado que la ocurrencia de esta palabra \'unicamente en $c$ es accidental, claramente no aporta informaci\'on suficiente para la clasificaci\'on y por tanto, al considerar lo contrario, aumenta el error.
		
		Este es uno de los prop\'positos que tiene la selecci\'on de t\'erminos (\emph{feature selection} (FS)). Esta consiste en reducir el vocabulario, considerado en la clasificaci\'on de textos solo un subconjunto del que aparece en el conjunto de entrenamiento. N\'otese que al disminuir el tama\~no del vocabulario aumenta la eficiencia de los m\'etodos de entrenamiento y clasificaci\'on (aunque no es el caso de NB).
		
		Selecci\'on de t\'erminos prefiere un clasificador m\'as simple antes que uno m\'as complejo. Esto es \'util cuando el conjunto de entrenamiento no es muy grande.
		
%		Nos concentraremos en describir la Selecci\'on de t\'erminos para la clasificaci\'on de dos clases.

		 En FS usualmente fijamos una cantidad $k$ de vocablos por cada clase $c$, que ser\'an los usados por el clasificador. Para seleccionar los $k$ t\'erminos deseados establecemos un ranking entre los t\'erminos de la clase, haciendo uso de una funci\'on de medida de utilidad $A(t,c)$, y nos quedamos con los $k$ mejor posicionados. El algoritmo b\'asico consiste en para cada clase $c$ iterar por todos los t\'erminos del vocabulario y computar su medida de utilidad para la clase; para finalmente ordenar los resultados y devolver una lista con los $k$ mejores.
		 
		 Presentaremos a continuaci\'on tres de los m\'etodos de calcular $A(t,c)$ m\'as comunes.
		
		\begin{itemize}
			\item\textbf{Informaci\'on Manual.}
			\smallskip
			
				Computar $A(t,c)$ como el valor esperado de informaci\'on mutua (\emph{Mutual Information} (MI)), nos da una medida de cu\'anta informaci\'on aporta, la presencia en $c$ de un t\'ermino dado, a tomar la decisi\'on correcta de clasificaci\'on de un documento. Lo definimos como \color{red}[Hay que poner aqui que esto se cogio del libro, pagina 272]\color{black}
				\[
					I(U_t;C_t) = \sum_{e_t \in \{ 1,0 \} } \sum_{e_c \in \{ 1,0 \} } P( U_t = e_t, C_t = e_c) \log_2 \frac{P (U_t = e_t, C_t = e_c) }{ P(U_t = e_t) P(C_t = e_c) },
				\]
				donde $U_t$ es una variable aleatoria que toma valor $e_t = 1$ si el documento contiene el t\'ermino $t$ y $e_t = 0$ en otro caso, y $C$ es otra variable aleatoria que toma valor $e_c = 1$ si el documento est\'a en la clase $c$ y $e_c = 0  $ en otro caso. 
				
				\smallskip
	
				MI mide cu\'anta informaci\'on un t\'ermino contiene acerca de una clase. Por tanto, mantener los t\'erminos que est\'an cargados de informaci\'on, y eliminar los que no, contribuye a reducir el ruido y mejorar la precisi\'on del clasificador.
	
			\smallskip
			\item\textbf{Selecci\'on Chi cuadrado $\chi^2$.} 
			\smallskip
			
			En estad\'istica se dice que dos eventos son independientes si el resultado de uno no afecta al resultado del otro. Esto se puede escribir formalmente como $P(AB) = P(A) P(B)$. En estad\'istica el test $\chi^2$ se usa para medir el grado de independencia de dos eventos. En FS podemos entonces considerar aplicar este test asumiendo como eventos la ocurrencia de los t\'erminos y la ocurrencia de las clases. Esto es \color{red} Esto tambien hay que poner de donde lo cogi (pag 275)\color{black} 
			\[
				\chi^2(D,t,c) = \sum_{e_t\in \{ 1, 0 \}} \sum_{e_c\in \{ 1, 0 \}} \frac{(N_{e_te_c} - E_{e_t e_c}) ^2 } { E_{e_t e_c}},
			\]
			donde $N$ es la frecuencia seg\'un $D$, $E$ es la frecuencia esperada y $e_t$ y  $e_c$ se definen como en la medida anterior.
			
			\smallskip
			\item \textbf{Selecci\'on basada en frecuencia}.
			\smallskip
			
			 Esta medida consiste en priorizar los t\'erminos que son m\'as comunes en la  clase. Puede ser calculada de dos formas diferentes. La primera es cantidad de repeticiones de un t\'ermino en los documentos de una clase, conocida como frecuencia en colecci\'on. La otra es frecuencia de documentos, y se calcula como la cantidad de documentos en la clase que contienen al t\'ermino en cuesti\'on.
			
			\smallskip
				
			Cuando son seleccionados varios miles de t\'erminos, entonces esta medida es bastante buena. Esta es preferible a otros m\'etodos m\'as complejos cuando se aceptan soluciones sub\'optimas.
			
		\end{itemize}
	\end{subsection}
	
	\subsection{K Nearest Neighbor}
	
		En el algoritmo de Naive Bayes represent\'abamos los documentos como vectores booleanos de t\'erminos. Luego vimos que hay t\'erminos que no eran relevantes y que aportaban ruido, y lo solucionamos seleccionando para el clasificador solamente un subconjunto de todos los t\'erminos. A\'un as\'i estamos clasificando la relevancia de cada t\'ermino de manera binaria en relevante o no relevante (que aporta ruido).
		
		 El m\'etodo que presentamos en esta secci\'on, as\'i como otros similares, asignan a cada t\'ermino cierto valor de importancia relativa al documento en que aparece. Para esto se cambia la representaci\'on de los documentos a vectores de $\mathbb{R}^{|V|}$, donde a cada componente corresponde cierto peso que se le asigna al t\'ermino correspondiente a esta. Entonces, el espacio de documentos $\mathcal{X}$ (dominio de $\gamma$) es $\mathbb{R}^{|V|}$. A esta forma de representaci\'on de documentos se le conoce como modelo de espacio de vectores. La hip\'otesis b\'asica para usar el modelo de espacio de vectores es la siguiente \color{red} citar adecuadamente : pagina 289 \color{black}
		 
		 \textbf{Hip\'otesis de contig\"uidad:} Documentos en la misma clase forman una regi\'on contigua  y regiones de diferentes clases no se superponen.
		 
		 Las decisiones de muchos clasificadores basados en espacio de vectores dependen de una noci\'on de distancia. Pueden ser usadas por ejemplo similitud basado en el coseno (del \'angulo formado entre los vectores) o distancia Euclideana. Por lo general no hay mucha diferencia entre usar una u otra de estas distancias.
		 
		 La tarea de la clasificaci\'on en el modelo de espacio de vectores es determinar las fronteras entre los documentos pertenecientes a una u otra clase. Estas \'ultimas son llamadas fronteras de decisi\'on ya que dividen el espacio en diferentes poliedros, tales que si un documento pertenece a uno determinado, autom\'aticamente sabemos de qu\'e clase es. 
		 
		 En K Nearest Neighbor la frontera de decisi\'on se determina localmente. En este asignamos cada documento a la misma clase que la mayor\'ia de los $k$ puntos m\'as cercanos al documento. Basado en la hip\'otsis de contig\"uidad esperamos que el documento $d$ pertenezca a la misma clase que aquellos m\'as cercanos a \'el.
		 
		En $kNN$ para subdividir el espacio de documentos en regiones, dado un $k \in \mathbb{N}$ fijo, consideramos cada regi\'on como el conjunto de puntos para los cuales los $k$ puntos m\'as cercanos son los mismos. Estas regiones son poliedros convexos. Luego para cada una de estas regiones existe una clase a la que pertenecen todos sus puntos, que es aquella a la que pertenecen la mayor\'ia de los documentos, ya clasificados, que est\'an dentro de la regi\'on. En caso de que haya empate, la decisi\'on de a que clase asignar a un nuevo documento que pertenece a esta regi\'on del espacio, es tomada aleatoriamente entre las clases empatadas.
		
		El par\'ametro $k$ es usualmente seleccionado basado en el conocimiento que se posee sobre los problemas de clasificaci\'on similares al que se tiene. Otra forma de seleccionar $k$ es usando conjuntos de documentos de prueba (ya clasificados) para ver que valor de $k$ producen mejores resultados.
		
		Tambi\'en hay variantes del m\'etodo donde lo que se hace es calcular una similitud entre el documento $d$ a clasificar y cada uno de los $k$ m\'as cercanos, usando, por ejemplo, el coseno entre los vectores. Luego se hace un ranking entre las clases a las que pertenecen cada uno de los $k$ puntos. Para ello se calcula para cada $c$, la suma de la similitud entre $d$ y cada uno de los puntos que pertenecen a $c$ y a la vez est\'an entre los $k$ mencionados. La siguiente funci\'on $score$ produce el resultado deseado
		\[
			score(c,d)  = \sum_{d'\in S_k(d)} I_c(d') \cos(\overrightarrow{v}(d'),\overrightarrow{v}(d)),
		\]
		donde $S_k(d)$ es el conjunto de los $k$ puntos m\'as cercanos a $d$ e $I_c(d')$ es $1$ o $0$ en dependencia de si $d'$ pertenece a la clase $c$ o no. Finalmente se selecciona para $d$ la clase $c$ que m\'as alto aparezca en el ranking. En ocasiones esta variante presenta mayor exactitud que la anterior.
		
		
		\begin{subsection}{Evaluaci\'on de la clasificaci\'on}
			
			Una alta exactitud en la clasificaci\'on de los datos de entrenamiento no necesariamente se traduce en resultados correctos en los nuevos documentos introducidos. Puede sucede que el sistema resulte sobreentrenado (\emph{over-fitting}) o subentrenado (\emph{under-fitting}). El primero de los casos ocurre cuando el modelo se encuentra con muchos datos. En este caso el sistema aprende de los ruidos y de las entradas inexactas lo que provoca que el clasificador aprenda incorrectamente a clasificar los elementos de alguna clase. Por otro lado under-fitting ocurre cuando el sistema tiene informaci\'on muy vaga sobre la frontera entre clases lo que provoca cierta aleatoriedad en la clasificaci\'on.
			
			Para evaluar la labor de un clasificador se debe emplear un conjunto de documentos diferentes al conjunto entrenante el cual se llama conjunto de prueba. Este debe estar en todo momento aislado del conjunto de entrenamiento. Si se juntan el clasificador puede aprender en su entrenamiento a reconocer los documentos del conjunto de prueba, y luego  al evaluar el mismo, el desempe\~no del sistema ser\'a mucho m\'as alto que el resultado real que tenga cuando se ponga en uso. Usualmente los datos que se tienen se dividen entre el conjunto entrenante y de prueba a raz\'on de $4:1$.
			
			Las siguientes tres m\'etricas pueden ser utilizadas para evaluar clasificadores de dos clases (c y \~c):	
					
			\begin{itemize}
				
				\item\textbf{Precisi\'on}
				
				\[
				Precision = \frac{\emph{N\'umero de documentos correctamente identificados como $c$} }{\emph{N\'umero de documentos identificados como $c$}}
				\]
				
				\item\textbf{Recobrado}
				
				\[
				recobrado = \frac{\emph{N\'umero de documentos correctamente identificados como $c$} }{\emph{N\'umero de documentos que pertenecen a $c$}}
				\]
				
				\item\textbf{Medida $F$} 
				
				\[
					F = 2 \times  \frac{Precision \times Recobrado}{Precision + Recobrado}
				\]
				
				
			\end{itemize}
			
			El mismo resultado se puede ver usando la matriz de contingencia. Una matriz de contingencia muestra de todas las pruebas realizadas con el clasificador, cu\'antas resultaron en verdadero positivo, falso positivo, falso negativo y verdadero negativo.
			
			En el caso que la cantidad de clases sea mayor que dos, podemos computar promedios entre las m\'etricas anteriores viendo el clasificador como uno de dos clases aplicado a cada clase $c$ (y su complemento). Existen dos promedios que son los m\'as usados para esto. Macropromedio calcula simplemente la media entre las medidas anteriores para cada clasificador de dos clases. Microaverage primero adiciona las matrices de contingencia correspondientes a diferentes clases y luego aplica una de las m\'etricas anteriores sobre la matriz resultante. 
			
			
			
		\end{subsection}
		
		\color{red}
		 NOTA:
		\begin{itemize}
			\item Ver lo de cuando estan hablando de clasificacion en dos clases y cuando no. 
			\item Podr\'ia insertarse una foto de la matriz de contingencia(pagina 16 de classification.pdf)
			\item Ver si agrego algo de clasificacion any-of
			\item agregar el c\'odigo del algoritmo de KNN.
			\item Ver lo de statistical classification que no me queda claro si toda lo que he escrito entra dentro de eso o no.
			\item citas correctas
		\end{itemize}
		\color{black}
		
		
		
		 
		 
		 
	
\begin{itemize}
	\item Aprendizaje supervisado
	
	\item Problema que resuelve
\end{itemize}

\begin{itemize}
\item Rule-based classification

\item Statistical classification

\item Feature selection

\item Medidas de evaluaci\'on:
\begin{itemize}
	\item Fitting
	\item Precisi\'on
	\item Recobrado
	\item Medida F (balanceada)
	\item Classification accuracy
\end{itemize}

\item Algoritmos:
\begin{itemize}
	\item Naive Bayes
	
	
	\item K-Nearest Neighbours
\end{itemize}
\end{itemize}

\subsection{Aplicaciones a la RI}
\begin{itemize}
	\item Standing queries
	\item Spam filtering
\end{itemize}

\subsection{Ventajas} 

\subsection{Desventajas}

\section{Agrupamiento vs. Clasificaci\'on}

\section{Ejemplos de aplicación}



\end{document}
